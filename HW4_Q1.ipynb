{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31OhJiXRc7hB"
      },
      "source": [
        "# Sajad Rahmanian 97101683"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgement\n",
        "This code is based on keras blog [post](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) about sequence to sequence models."
      ],
      "metadata": {
        "id": "b3hNCSSvCqZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Necessary Packages"
      ],
      "metadata": {
        "id": "P7pS_EDF_2eF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "CId-F_Y1dPwr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, LSTM, Dense, Embedding, GRU\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR66vbufdDP7"
      },
      "source": [
        "# Getting the dataset ready"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlToy6bPc3g-",
        "outputId": "0660a826-dbd7-4e52-960f-31ccee465e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['به نام خداوند جان و خرد', 'کزین برتر اندیشه برنگذرد', 'خداوند نام و خداوند جای', 'خداوند روزی ده رهنمای', 'خداوند کیوان و گردان سپهر']\n",
            "['\\t', '\\n', ' ', '(', ')', '«', '»', '،', '؟', 'ء', 'آ', 'أ', 'ؤ', 'ئ', 'ا', 'ب', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ف', 'ق', 'ل', 'م', 'ن', 'ه', 'و', 'ٔ', 'پ', 'چ', 'ژ', 'ک', 'گ', 'ی']\n",
            "به نام خداوند جان و خرد کزین برتر اندیشه برنگذرد\n"
          ]
        }
      ],
      "source": [
        "# Read the text file and split its lines:\n",
        "with open(\"ferdousi.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "    text = f.read().splitlines()\n",
        "# Remove the first two lines:\n",
        "text = text[2:]\n",
        "print(text[:5])\n",
        "# Get the unique chars (add '\\n' and '\\t' to chars list)\n",
        "joined_text = \" \".join(text)\n",
        "joined_text_d = joined_text + \"\\n\\t\"\n",
        "chars = sorted(set(joined_text_d))\n",
        "print(chars)\n",
        "# Join mesraes (!) to create beyts (!)\n",
        "m1 = text[0::2]\n",
        "m2 = text[1::2]\n",
        "beyts = [\" \".join([x, y]) for x, y in zip(m1, m2)]\n",
        "print(beyts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoqTNJt4movA",
        "outputId": "da8ca260-a2c4-4e66-de7f-95b66da069f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n"
          ]
        }
      ],
      "source": [
        "# number of unique chars (vocab_size)\n",
        "n_chars = len(chars)\n",
        "print(n_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meJth2AR0GcC",
        "outputId": "7f790b0b-2310-4376-9fdc-b5cbdc756e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n"
          ]
        }
      ],
      "source": [
        "# maximum length of a beyt in dataset\n",
        "max_beyt_len = max([len(x) for x in beyts])\n",
        "print(max_beyt_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "TTlC-A551ajp"
      },
      "outputs": [],
      "source": [
        "# define mappings from chars to their index and vice versa\n",
        "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx_to_char = {i: ch for i, ch in enumerate(chars)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui2_-Ef21HhH",
        "outputId": "23ca0fae-c13c-4133-fb79-8434cd124883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49607, 49607)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# define input and output beyts\n",
        "# for each input beyt, the output is its following beyt\n",
        "# \"\\t\" and \"\\n\" represent the start and end of target outputs (this is needed for prediction)\n",
        "input_texts = beyts[:-1]\n",
        "output_texts = [\"\\t\" + txt + \"\\n\" for txt in beyts[1:]]\n",
        "len(input_texts), len(output_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "iHdy9v7N7rFZ"
      },
      "outputs": [],
      "source": [
        "# map chars to their respective indices\n",
        "# decoder_out is ahead of its input by one character\n",
        "encoder_inputs_raw = [[char_to_idx[ch] for ch in sent] for sent in input_texts]\n",
        "decoder_inputs_raw = [[char_to_idx[ch] for ch in sent] for sent in output_texts]\n",
        "decoder_outputs_raw = [[char_to_idx[ch] for ch in sent[1:]] for sent in output_texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XqW400dz_i_-"
      },
      "outputs": [],
      "source": [
        "# pad the sequences to maximum length of beyts\n",
        "# space char is used for padding\n",
        "encoder_inputs_padded = pad_sequences(encoder_inputs_raw,\n",
        "                                      maxlen=max_beyt_len,\n",
        "                                      padding='post',\n",
        "                                      value=char_to_idx[' '])\n",
        "decoder_inputs_padded = pad_sequences(decoder_inputs_raw,\n",
        "                                      maxlen=max_beyt_len,\n",
        "                                      padding='post',\n",
        "                                      value=char_to_idx[' '])\n",
        "decoder_outputs_padded = pad_sequences(decoder_outputs_raw,\n",
        "                                       maxlen=max_beyt_len,\n",
        "                                       padding='post',\n",
        "                                       value=char_to_idx[' '])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining and training the end to end model\n",
        "\n",
        "Read the comments for explanations"
      ],
      "metadata": {
        "id": "Dq-jDQnjAJjo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hQWZ4jhCO49V"
      },
      "outputs": [],
      "source": [
        "# PARAMS:\n",
        "# Number of units in recurrent layers\n",
        "RNN_UNITS = 1024\n",
        "# Embedding dimension of chars\n",
        "EMBEDDING_DIM = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "azX4iBjqCkA9"
      },
      "outputs": [],
      "source": [
        "# Get end to end model\n",
        "def get_end_to_end_model(input_length=max_beyt_len,\n",
        "                         vocab_size=n_chars, \n",
        "                         rnn_units=256,\n",
        "                         embedding_dim=256,\n",
        "                         rnn_type=\"LSTM\"):\n",
        "\n",
        "    # Input is a beyt with maximum length\n",
        "    raw_enc_inputs = Input(shape=(input_length,))\n",
        "    # Embed the input beyt to an embedding_dim size vector\n",
        "    enc_embedder = Embedding(vocab_size, embedding_dim)\n",
        "    enc_embedded_inputs = enc_embedder(raw_enc_inputs)\n",
        "\n",
        "    if rnn_type == \"LSTM\":\n",
        "        # Define recurrent layer. The output of encoder is not needed --> return_sequences=False\n",
        "        enc_rnn_layer = LSTM(rnn_units, return_sequences=False, return_state=True)\n",
        "        # Get the output state of the encoder\n",
        "        _, enc_h, enc_c = enc_rnn_layer(enc_embedded_inputs)\n",
        "        enc_states = [enc_h, enc_c]\n",
        "    elif rnn_type == \"GRU\":\n",
        "        enc_rnn_layer = GRU(rnn_units, return_sequences=False, return_state=True)\n",
        "        _, enc_states = enc_rnn_layer(enc_embedded_inputs)\n",
        "    else:\n",
        "        raise NotImplemented\n",
        "\n",
        "    # Input sequence of decoder\n",
        "    raw_dec_inputs = Input(shape=(input_length,))\n",
        "    # Embedding decoder input\n",
        "    dec_embedder = Embedding(vocab_size, embedding_dim)\n",
        "    dec_embedded_inputs = dec_embedder(raw_dec_inputs)\n",
        "\n",
        "    if rnn_type == \"LSTM\":\n",
        "        # Recurrent layer of decoder. We need its outputs --> return_sequences=True\n",
        "        dec_rnn_layer = LSTM(rnn_units, return_sequences=True, return_state=True)\n",
        "        dec_outputs, _, _ = dec_rnn_layer(dec_embedded_inputs, initial_state=enc_states)\n",
        "    elif rnn_type == \"GRU\":\n",
        "        dec_rnn_layer = GRU(rnn_units, return_sequences=True, return_state=True)\n",
        "        dec_outputs, _ = dec_rnn_layer(dec_embedded_inputs, initial_state=enc_states)\n",
        "    \n",
        "    # From dec_outputs we need to predict the character \n",
        "    # --> the output size of the dense layer is equal to vocab_size (n_chars)\n",
        "    dec_dense = Dense(vocab_size, activation=\"softmax\")\n",
        "    dec_output = dec_dense(dec_outputs)\n",
        "    # For training the inputs of the model are: input beyt and target output beyt\n",
        "    # The output of the model is the predicted output beyt\n",
        "    model = Model([raw_enc_inputs, raw_dec_inputs], dec_output)\n",
        "\n",
        "    return model    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM"
      ],
      "metadata": {
        "id": "Mjx_w30oBooK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "6NNimCKAjb0k"
      },
      "outputs": [],
      "source": [
        "# Get the model with LSTM\n",
        "model_lstm = get_end_to_end_model(rnn_units=RNN_UNITS,\n",
        "                                  embedding_dim=EMBEDDING_DIM,\n",
        "                                  rnn_type=\"LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQASdcyyyNhW",
        "outputId": "e93879b8-34c8-4f70-e8d2-52ef0abe83b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "621/621 [==============================] - 57s 88ms/step - loss: 1.4699 - accuracy: 0.5668 - val_loss: 1.2203 - val_accuracy: 0.6383\n",
            "Epoch 2/10\n",
            "621/621 [==============================] - 57s 91ms/step - loss: 1.0851 - accuracy: 0.6694 - val_loss: 1.1261 - val_accuracy: 0.6638\n",
            "Epoch 3/10\n",
            "621/621 [==============================] - 56s 90ms/step - loss: 1.0024 - accuracy: 0.6922 - val_loss: 1.0767 - val_accuracy: 0.6787\n",
            "Epoch 4/10\n",
            "621/621 [==============================] - 57s 92ms/step - loss: 0.9452 - accuracy: 0.7087 - val_loss: 1.0497 - val_accuracy: 0.6883\n",
            "Epoch 5/10\n",
            "621/621 [==============================] - 57s 91ms/step - loss: 0.9006 - accuracy: 0.7219 - val_loss: 1.0349 - val_accuracy: 0.6932\n",
            "Epoch 6/10\n",
            "621/621 [==============================] - 56s 91ms/step - loss: 0.8637 - accuracy: 0.7328 - val_loss: 1.0263 - val_accuracy: 0.6968\n",
            "Epoch 7/10\n",
            "621/621 [==============================] - 56s 90ms/step - loss: 0.8273 - accuracy: 0.7434 - val_loss: 1.0287 - val_accuracy: 0.6992\n",
            "Epoch 8/10\n",
            "621/621 [==============================] - 56s 90ms/step - loss: 0.7957 - accuracy: 0.7527 - val_loss: 1.0313 - val_accuracy: 0.7001\n",
            "Epoch 9/10\n",
            "621/621 [==============================] - 56s 90ms/step - loss: 0.7715 - accuracy: 0.7600 - val_loss: 1.0427 - val_accuracy: 0.6984\n",
            "Epoch 10/10\n",
            "621/621 [==============================] - 56s 90ms/step - loss: 0.7447 - accuracy: 0.7682 - val_loss: 1.2476 - val_accuracy: 0.6518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model_lstm.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history = model_lstm.fit(\n",
        "    [encoder_inputs_padded, decoder_inputs_padded],\n",
        "    decoder_outputs_padded,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "model_lstm.save(\"end_to_end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "OjDyCHdRvLGt",
        "outputId": "be747608-0d1b-4eb7-f224-5517314bb771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 619ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'اوایند پاپ ج نرایسد بزی نوایند بخز\\n بگ وو م ی                   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "test_out = model_lstm.predict(\n",
        "    [encoder_inputs_padded[:1], decoder_inputs_padded[:1]]).argmax(2)\n",
        "t = \"\"\n",
        "for x in test_out[0]:\n",
        "    t+= idx_to_char[x]\n",
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "tEAopzYw8FHS"
      },
      "outputs": [],
      "source": [
        "def get_enc_dec_models(e2e_model, rnn_units=256, rnn_type=\"LSTM\"):\n",
        "    # We need to separate the encoder and decoder for generating sequences\n",
        "\n",
        "    # the first input of the model is the input to the encoder\n",
        "    enc_inputs = e2e_model.input[0]\n",
        "    if rnn_type == \"LSTM\":\n",
        "      # Get encoder states from lstm layer\n",
        "      _, enc_state_h_, enc_state_c_ = e2e_model.layers[4].output\n",
        "      enc_states = [enc_state_h_, enc_state_c_]\n",
        "      # Define the encoder with inputs defined as above,\n",
        "      # and the outputs defined as its states\n",
        "      enc_model = Model(enc_inputs, enc_states)\n",
        "      # Decoder model input is the e2e model second input\n",
        "      dec_inputs = e2e_model.input[1]\n",
        "      # The decoder also gets its initial states from encoder or itself\n",
        "      dec_input_states_h = Input((rnn_units,))\n",
        "      dec_input_states_c = Input((rnn_units,))\n",
        "      # Get the outputs of decoder lstm layer\n",
        "      # Note that the input to the lstm layer should come from embedding layer\n",
        "      dec_outputs, dec_output_states_h, dec_output_states_c = e2e_model.layers[5](\n",
        "          e2e_model.layers[3](dec_inputs), # or e2e_model.layers[3](dec_inputs) # e2e_model.layers[3].output\n",
        "          initial_state=[dec_input_states_h,dec_input_states_c])\n",
        "      # Get dense layer's output\n",
        "      dec_output = e2e_model.layers[6](dec_outputs)\n",
        "      # Decoder inputs: inputs char, input states\n",
        "      # Decoder outputs: pred_char_probs, output states\n",
        "      dec_model = Model([dec_inputs,\n",
        "                         dec_input_states_h,\n",
        "                         dec_input_states_c],\n",
        "                        [dec_output,\n",
        "                         dec_output_states_h,\n",
        "                         dec_output_states_c])\n",
        "\n",
        "    elif rnn_type == \"GRU\":\n",
        "        _, enc_states = e2e_model.layers[4].output\n",
        "        enc_model = Model(enc_inputs, enc_states)\n",
        "        dec_inputs = e2e_model.input[1]\n",
        "        dec_input_states = Input((rnn_units,))\n",
        "        dec_outputs, dec_output_states = e2e_model.layers[5](\n",
        "            e2e_model.layers[3](dec_inputs),\n",
        "            initial_state=dec_input_states)\n",
        "        dec_output = e2e_model.layers[6](dec_outputs)\n",
        "        dec_model = Model([dec_inputs,\n",
        "                           dec_input_states],\n",
        "                          [dec_output,\n",
        "                           dec_output_states])\n",
        "    else:\n",
        "        raise NotImplemented\n",
        "\n",
        "    return enc_model, dec_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "q4PPmIBbBIPi"
      },
      "outputs": [],
      "source": [
        "encoder_model, decoder_model = get_enc_dec_models(model_lstm, rnn_units=RNN_UNITS, rnn_type=\"LSTM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating function\n",
        "\n",
        "When we want to generate a beyt from input beyt, we first feed the input beyt into encoder to get the initial state for decoder. Then, we use this initial state and start character ('\\t') to predict next character. Then output state and the predicted character are fed to the decoder to predict next character, and so on."
      ],
      "metadata": {
        "id": "mmHtNC55BujU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8xm33scXjsLm"
      },
      "outputs": [],
      "source": [
        "def generate_beyt(input_beyt, encoder, decoder, rnn_type, generation_type=\"best\"):\n",
        "    # Set the first char to start char which is '\\t'\n",
        "    next_char = \"\\t\"\n",
        "    # Output beyt to be completed\n",
        "    out_beyt = \"\"\n",
        "    if rnn_type == \"LSTM\":\n",
        "        # At first the decoder initial state should come from the encoder\n",
        "        h_st, c_st = encoder(input_beyt, training=False)\n",
        "        # We fill the output layer until we reach end of seq char or maximum length of beyts\n",
        "        while next_char != \"\\n\" and len(out_beyt) <= max_beyt_len:\n",
        "        # The next initial states come from the decoder itself\n",
        "            probs, h_st, c_st = decoder([np.array(char_to_idx[next_char], int).reshape((1,1)),\n",
        "                                                 h_st,\n",
        "                                                 c_st],\n",
        "                                        training=False)\n",
        "            probs = probs.numpy().flatten()\n",
        "            if generation_type == \"best\":\n",
        "                next_char = idx_to_char[probs.argmax()]\n",
        "            elif generation_type == \"sampling\":\n",
        "                next_char = idx_to_char[np.random.choice(range(len(probs)), p=probs)]\n",
        "            # Add char to output\n",
        "            out_beyt += next_char\n",
        "    elif rnn_type == \"GRU\":\n",
        "        # At first the decoder initial state should come from the encoder\n",
        "        st = encoder(input_beyt, training=False)\n",
        "        # We fill the output layer until we reach end of seq char or maximum length of beyts\n",
        "        while next_char != \"\\n\" and len(out_beyt) <= max_beyt_len:\n",
        "        # The next initial states come from the decoder itself\n",
        "            probs, st = decoder([np.array(char_to_idx[next_char], int).reshape((1,1)), st], training=False)\n",
        "            probs = probs.numpy().flatten()\n",
        "            if generation_type == \"best\":\n",
        "                next_char = idx_to_char[probs.argmax()]\n",
        "            elif generation_type == \"sampling\":\n",
        "                next_char = idx_to_char[np.random.choice(range(len(probs)), p=probs)]\n",
        "            # Add char to output\n",
        "            out_beyt += next_char\n",
        "\n",
        "    return out_beyt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two generation modes:\n",
        "1. Use the most probable character each time (argmax)\n",
        "2. Sample from the chars with probabilities equaling the softmax output\n",
        "\n",
        "The second method is better for generating different outputs"
      ],
      "metadata": {
        "id": "nbxdM3gVB1Iq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9pthQT8jiHj",
        "outputId": "55dcbd73-46ac-4916-ab82-9ad88169783c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: نهادند خوان پیش ایزدگشسب گرفتند پس واژ و برسم بدست              \n",
            "Output Sequence: به پیش اندرون باره بردش نماز به نزدیک شاه آمد از بارگاه\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: بران سان که شاهان نوازش کنند بران بندگان نیز نازش کنند          \n",
            "Output Sequence: از گرد برنگذرد پیش او بر دل این داستان بر فزود\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نخواهم بدن زنده بی روی او جهانم نیرزد به یک موی او              \n",
            "Output Sequence: به گفتار این نامدار اردشیر که با من به جنگ اندر آید سپید\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: برآمد ز زاولستان رستخیز زمین خفته را بانگ برزد که خیز           \n",
            "Output Sequence: از گرد برنگذرد پیش او بر دل این داستان بر فزود\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: پیاده به پیش اندر افگند خوار به لشکرگه آوردش از کارزار          \n",
            "Output Sequence: به پیش اندرون باره بردش نماز به نزدیک شاه آمد از بارگاه\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: به ایران مرا کار زین بهترست همم کردگار جهان یاورست              \n",
            "Output Sequence: از گرد برنگذرد پیش او بر دل این داستان بر فزود\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: ببایست برگشتن از رزمگاه که گرد سپه بود و شب شد سیاه             \n",
            "Output Sequence: از گرد برنگذرد پیش او بر دل این داستان بر فزود\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: چنین بود تا بود دور زمان بنوی تو اندر شگفتی ممان                \n",
            "Output Sequence: به پیش اندرون باره بردش نماز به نزدیک شاه آمد از بارگاه\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نه فرزندم ایدر نه چون چاکری نه چون کهتری شاددل بر دری           \n",
            "Output Sequence: به پیش اندرون باره بردش نماز به نزدیک شاه آمد از بارگاه\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: همان با خردمند گیرد ستیز کند دل ز نادانی خویش تیز               \n",
            "Output Sequence: از گرد برنگذرد پیش او بر دل این داستان بر فزود\n",
            "\n",
            "--------------------------------------\n"
          ]
        }
      ],
      "source": [
        "test_indices = np.arange(len(encoder_inputs_padded))\n",
        "np.random.shuffle(test_indices)\n",
        "test_indices = test_indices[:10]\n",
        "for idx in test_indices:\n",
        "    in_seq = encoder_inputs_padded[idx:idx+1]\n",
        "    out_seq = generate_beyt(in_seq, encoder_model, decoder_model, \"LSTM\", \"best\")\n",
        "    in_seq_chars = \"\"\n",
        "    for i in in_seq[0]:\n",
        "        in_seq_chars += idx_to_char[i]\n",
        "    print(f\"Input Sequence: {in_seq_chars}\")\n",
        "    print(f\"Output Sequence: {out_seq}\")\n",
        "    print(\"--------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "DSblpHV3TnR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9900666a-d68c-44b2-e6d6-06ef15713f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: نهادند خوان پیش ایزدگشسب گرفتند پس واژ و برسم بدست              \n",
            "Output Sequence: پس آنگه گرفت آنگهی انجمن گرفتند هر دو بوردگاه به زین\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: بران سان که شاهان نوازش کنند بران بندگان نیز نازش کنند          \n",
            "Output Sequence: راهی و تاج مهان\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نخواهم بدن زنده بی روی او جهانم نیرزد به یک موی او              \n",
            "Output Sequence: مجو ایمن از کار من چون بهشت چنان دان که بر خیزد آن فر و برگ\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: برآمد ز زاولستان رستخیز زمین خفته را بانگ برزد که خیز           \n",
            "Output Sequence: از شرم نیزه وراند پذیره شدنده ز آتش بره برنداشت\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: پیاده به پیش اندر افگند خوار به لشکرگه آوردش از کارزار          \n",
            "Output Sequence: همان نیز شادی بر اسبان شدند بد و بوم و آخوبی و نیست مرد گرفت آگهی\n",
            "--------------------------------------\n",
            "Input Sequence: به ایران مرا کار زین بهترست همم کردگار جهان یاورست              \n",
            "Output Sequence: همی لشکر آرام باش جوان پیر گفت وگفادم پذیری بیاراست داد\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: ببایست برگشتن از رزمگاه که گرد سپه بود و شب شد سیاه             \n",
            "Output Sequence: بشنگیریم یک خرد\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: چنین بود تا بود دور زمان بنوی تو اندر شگفتی ممان                \n",
            "Output Sequence: وزان پس جهاندیدگان را بخواست به گودرز گفتند ایران رسد\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نه فرزندم ایدر نه چون چاکری نه چون کهتری شاددل بر دری           \n",
            "Output Sequence: بیفگند یک روز و جای نبرد همین از پی کاه و سالار و گرد\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: همان با خردمند گیرد ستیز کند دل ز نادانی خویش تیز               \n",
            "Output Sequence: ازو الماس گفتند جای\n",
            "\n",
            "--------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for idx in test_indices:\n",
        "    in_seq = encoder_inputs_padded[idx:idx+1]\n",
        "    out_seq = generate_beyt(in_seq, encoder_model, decoder_model, \"LSTM\", \"sampling\")\n",
        "    in_seq_chars = \"\"\n",
        "    for i in in_seq[0]:\n",
        "        in_seq_chars += idx_to_char[i]\n",
        "    print(f\"Input Sequence: {in_seq_chars}\")\n",
        "    print(f\"Output Sequence: {out_seq}\")\n",
        "    print(\"--------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GRU"
      ],
      "metadata": {
        "id": "sCxMJUvQCQXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model with GRU\n",
        "model_gru = get_end_to_end_model(rnn_units=RNN_UNITS,\n",
        "                                  embedding_dim=EMBEDDING_DIM,\n",
        "                                  rnn_type=\"GRU\")"
      ],
      "metadata": {
        "id": "oRdHrw58-Hur"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "history_gru = model_gru.fit(\n",
        "    [encoder_inputs_padded, decoder_inputs_padded],\n",
        "    decoder_outputs_padded,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "model_gru.save(\"end_to_end_gru\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6q3uKt3-Mda",
        "outputId": "a1a73036-3982-4b8c-83f4-6c305b5fafb0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "621/621 [==============================] - 50s 76ms/step - loss: 1.7763 - accuracy: 0.4977 - val_loss: 1.4043 - val_accuracy: 0.5894\n",
            "Epoch 2/10\n",
            "621/621 [==============================] - 46s 74ms/step - loss: 1.2053 - accuracy: 0.6387 - val_loss: 1.1810 - val_accuracy: 0.6507\n",
            "Epoch 3/10\n",
            "621/621 [==============================] - 47s 75ms/step - loss: 1.0599 - accuracy: 0.6774 - val_loss: 1.1196 - val_accuracy: 0.6683\n",
            "Epoch 4/10\n",
            "621/621 [==============================] - 46s 75ms/step - loss: 0.9844 - accuracy: 0.6985 - val_loss: 1.0794 - val_accuracy: 0.6799\n",
            "Epoch 5/10\n",
            "621/621 [==============================] - 46s 74ms/step - loss: 0.9319 - accuracy: 0.7137 - val_loss: 1.0589 - val_accuracy: 0.6878\n",
            "Epoch 6/10\n",
            "621/621 [==============================] - 46s 74ms/step - loss: 0.8908 - accuracy: 0.7256 - val_loss: 1.0517 - val_accuracy: 0.6922\n",
            "Epoch 7/10\n",
            "621/621 [==============================] - 46s 74ms/step - loss: 0.8444 - accuracy: 0.7392 - val_loss: 1.0495 - val_accuracy: 0.6933\n",
            "Epoch 8/10\n",
            "621/621 [==============================] - 46s 74ms/step - loss: 0.8210 - accuracy: 0.7459 - val_loss: 1.0551 - val_accuracy: 0.6953\n",
            "Epoch 9/10\n",
            "621/621 [==============================] - 47s 76ms/step - loss: 0.7797 - accuracy: 0.7580 - val_loss: 1.0716 - val_accuracy: 0.6923\n",
            "Epoch 10/10\n",
            "621/621 [==============================] - 46s 75ms/step - loss: 0.7903 - accuracy: 0.7545 - val_loss: 1.0771 - val_accuracy: 0.6937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model_gru, decoder_model_gru = get_enc_dec_models(model_gru, rnn_units=RNN_UNITS, rnn_type=\"GRU\")"
      ],
      "metadata": {
        "id": "1889E66M-h8v"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_indices = np.arange(len(encoder_inputs_padded))\n",
        "# np.random.shuffle(test_indices)\n",
        "# test_indices = test_indices[:10]\n",
        "for idx in test_indices:\n",
        "    in_seq = encoder_inputs_padded[idx:idx+1]\n",
        "    out_seq = generate_beyt(in_seq, encoder_model_gru, decoder_model_gru, \"GRU\", \"best\")\n",
        "    in_seq_chars = \"\"\n",
        "    for i in in_seq[0]:\n",
        "        in_seq_chars += idx_to_char[i]\n",
        "    print(f\"Input Sequence: {in_seq_chars}\")\n",
        "    print(f\"Output Sequence: {out_seq}\")\n",
        "    print(\"--------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwm_sEW2-oLX",
        "outputId": "20c0148b-c439-4a2a-df34-824f923eddcc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: نهادند خوان پیش ایزدگشسب گرفتند پس واژ و برسم بدست              \n",
            "Output Sequence: به پیش سپاه اندرون با کمر همی خواست کاید به تنگی فراز\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: بران سان که شاهان نوازش کنند بران بندگان نیز نازش کنند          \n",
            "Output Sequence: به دژ بر یکی بانگ برزد به خون به دیدار او بر تن آسان شون\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نخواهم بدن زنده بی روی او جهانم نیرزد به یک موی او              \n",
            "Output Sequence: به پیش سپاه اندرون با کمر همی خواست کاید به تنگی فراز\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: برآمد ز زاولستان رستخیز زمین خفته را بانگ برزد که خیز           \n",
            "Output Sequence: به دژ بر یکی بانگ برزد به خون به دیدار او بر تن آسان شون\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: پیاده به پیش اندر افگند خوار به لشکرگه آوردش از کارزار          \n",
            "Output Sequence: به دژ بر یکی بانگ برزد به خون به دیدار او بر تن آسان شون\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: به ایران مرا کار زین بهترست همم کردگار جهان یاورست              \n",
            "Output Sequence: به دژ بر یکی بانگ برزد به خون به دیدار او بر تن آسان شون\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: ببایست برگشتن از رزمگاه که گرد سپه بود و شب شد سیاه             \n",
            "Output Sequence: به دژ بر یکی بانگ برزد به خون به دیدار او بر تن آسان شون\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: چنین بود تا بود دور زمان بنوی تو اندر شگفتی ممان                \n",
            "Output Sequence: به دیگر چو با من به راه آوریم به نزدیک شاه آمد اندر نهفت\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نه فرزندم ایدر نه چون چاکری نه چون کهتری شاددل بر دری           \n",
            "Output Sequence: به پیش سپاه اندرون با کمر همی خواست کاید به تنگی فراز\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: همان با خردمند گیرد ستیز کند دل ز نادانی خویش تیز               \n",
            "Output Sequence: به دژ بر یکی بانگ برزد به خون به دیدار او بر تن آسان شون\n",
            "\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in test_indices:\n",
        "    in_seq = encoder_inputs_padded[idx:idx+1]\n",
        "    out_seq = generate_beyt(in_seq, encoder_model_gru, decoder_model_gru, \"GRU\", \"sampling\")\n",
        "    in_seq_chars = \"\"\n",
        "    for i in in_seq[0]:\n",
        "        in_seq_chars += idx_to_char[i]\n",
        "    print(f\"Input Sequence: {in_seq_chars}\")\n",
        "    print(f\"Output Sequence: {out_seq}\")\n",
        "    print(\"--------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWkBj3D9-3m7",
        "outputId": "529deac7-3df2-4373-8304-11f3d933ab4d"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: نهادند خوان پیش ایزدگشسب گرفتند پس واژ و برسم بدست              \n",
            "Output Sequence: پدر چنگ چندی برفت و به رود همی لشکر و دشت بارآلگوش\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: بران سان که شاهان نوازش کنند بران بندگان نیز نازش کنند          \n",
            "Output Sequence: که تو شاه را یک به یکی درور چه چاچیز مانیم خوبی و گوش\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نخواهم بدن زنده بی روی او جهانم نیرزد به یک موی او              \n",
            "Output Sequence: چنین داد پاسخ که این داستان مگر پاک ماند به گرمان مکاش\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: برآمد ز زاولستان رستخیز زمین خفته را بانگ برزد که خیز           \n",
            "Output Sequence: یکی شارستان این بر نیمروز برافراخته سر پر از خون زوار\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: پیاده به پیش اندر افگند خوار به لشکرگه آوردش از کارزار          \n",
            "Output Sequence: یکی شارستان نام بر پهلوی که رخشنده شمع و شب آباد چوی\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: به ایران مرا کار زین بهترست همم کردگار جهان یاورست              \n",
            "Output Sequence: سراسر همه نامداران مشت ز خشنودی و کینه کشته بدست\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: ببایست برگشتن از رزمگاه که گرد سپه بود و شب شد سیاه             \n",
            "Output Sequence: چو ان کوه را دید بینی به پیش به دیدار او خانه آن آبگیر\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: چنین بود تا بود دور زمان بنوی تو اندر شگفتی ممان                \n",
            "Output Sequence: بجویم غمی گشت و بر شاه را نیایم نه زان نیز بی بارگی\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: نه فرزندم ایدر نه چون چاکری نه چون کهتری شاددل بر دری           \n",
            "Output Sequence: و دیگر چو تن با سلیح نبرد بیاراست لشکر بکام نبرد\n",
            "\n",
            "--------------------------------------\n",
            "Input Sequence: همان با خردمند گیرد ستیز کند دل ز نادانی خویش تیز               \n",
            "Output Sequence: پر اندیشه گفت آن زمان سی هزار که بر دین فریدون کساناران\n",
            "\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YgMnpDS7_A2Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}